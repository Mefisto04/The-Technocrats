<!DOCTYPE html>
<html>
<head>
    <title>Online Meeting</title>
    <style>
        /* styles.css */

body {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    height: 100vh;
    margin: 0;
    background-color: #191919;
}

.container {
    text-align: center;
}

#video-container {
    display: flex;
    justify-content: space-around;
}

#local-video, #remote-video {
    width: 45%;
    border: 1px solid #ccc;
    border-radius: 5px;
}

.controls {
    display: flex;
    justify-content: center;
    margin: 20px 0;
}

button {
    padding: 10px 20px;
    margin: 0 10px;
    background-color: #0074cc;
    color: #fff;
    border: none;
    border-radius: 5px;
    cursor: pointer;
    transition: background-color 0.3s;
}

button:hover {
    background-color: #0056b3;
}
a{
    text-decoration: none;
    color: white;
}

    </style>
</head>
<body>
    <div id="video-container">
        <video id="local-video" autoplay muted></video>
        <video id="remote-video" autoplay></video>
    </div>

    <div class="controls">
        <button id="mute-button">Mute</button>
        <button id="video-toggle-button">Video On/Off</button>
        <button id="end-call-button"><a href="main.html">End Call</a></button>
    </div>

    <div>
        <label style="color: white;">Meeting Link: <span id="meeting-link"></span></label>
    </div>

    <script>
        // JavaScript code for the online meeting

// Step 1: Get access to the user's camera and microphone
navigator.mediaDevices.getUserMedia({ video: true, audio: true })
    .then(function (localStream) {
        const localVideo = document.getElementById("local-video");
        localVideo.srcObject = localStream;

        // Step 2: Create a PeerConnection object for establishing a connection
        const peerConnection = new RTCPeerConnection();

        // Step 3: Add the local stream to the connection
        localStream.getTracks().forEach(track => peerConnection.addTrack(track, localStream));

        // Step 4: Create an offer to initiate the call
        peerConnection.createOffer()
            .then(function (offer) {
                return peerConnection.setLocalDescription(offer);
            })
            .then(function () {
                // Offer can be sent to the other participant via signaling server
                // Implement signaling server for real-world applications
            });

        // Step 5: Implement the signaling server for offer and answer exchange

        // Step 6: Handle incoming offers and answers

        // Step 7: When an answer is received
        function handleAnswer(answer) {
            const remoteDescription = new RTCSessionDescription(answer);
            peerConnection.setRemoteDescription(remoteDescription);
        }

        // Step 8: Handle incoming ICE candidates

        // Step 9: When an ICE candidate is received
        function handleCandidate(candidate) {
            const iceCandidate = new RTCIceCandidate(candidate);
            peerConnection.addIceCandidate(iceCandidate);
        }
    })
    .catch(function (error) {
        console.error("Error accessing media devices:", error);
    });

// Step 10: Implement functionality to toggle mute, video on/off, and end call
// JavaScript code for the online meeting

// Track variables for mute and video status
let isMuted = false;
let isVideoOn = true;

const localVideo = document.getElementById("local-video");
const remoteVideo = document.getElementById("remote-video");
const muteButton = document.getElementById("mute-button");
const videoToggleButton = document.getElementById("video-toggle-button");
const endCallButton = document.getElementById("end-call-button");
const meetingLink = document.getElementById("meeting-link");

// Function to toggle mute and update button text
function toggleMute() {
    const localStream = localVideo.srcObject;
    localStream.getAudioTracks().forEach(track => {
        track.enabled = !isMuted;
    });
    isMuted = !isMuted;
    muteButton.textContent = isMuted ? "Unmute" : "Mute";
}

// Function to toggle video on/off and update button text
function toggleVideo() {
    const localStream = localVideo.srcObject;
    localStream.getVideoTracks().forEach(track => {
        track.enabled = isVideoOn;
    });
    isVideoOn = !isVideoOn;
    videoToggleButton.textContent = isVideoOn ? "Video Off" : "Video On";
}

// Function to end the call
function endCall() {
    // Close the connection and release media resources
    // Implement this based on your WebRTC setup
}

muteButton.addEventListener("click", toggleMute);
videoToggleButton.addEventListener("click", toggleVideo);
endCallButton.addEventListener("click", endCall);

// Rest of the WebRTC code (offer, answer, signaling, ICE handling, etc.) here


    </script>
</body>
</html>
